## 4.1.3 Analyse des données : codage des entretiens en utilisant un système permettant d'identifier les barrières socio-techniques et les moyens imaginés pour les lever

Dans cette section, nous décrivons les cas de la métropôle Grenoble-Alpes et de la métropole du Grand Lyon. Nous décrivons dans chacun de ces cas les différentes étapes de l'usage de données, telle que décrites dans le framework construit dans le [chapitre précédent](3.1.3_explo_connaissance_formation.md), ainsi que les barrières que les barrières rencontrées par les praticiens. Sur le base de ces descriptions nous identifierons dans la prochaine section les besoins fonctionnels qu'une intervention en système d'information doit combler pour lever ces barrières. 

### Utilisation des fonctionnalités de la plateformes (téléchargement/flux de données)

` 1. Quelle forme les interfaces de données prennent-elles ? 
  2. Quelles sont les conditions d'interactions des utilisateurs avec les interfaces`
` 3. Quelles sont les barrières qui empêchent le complémentarité des interfaces avec les conditions d'interaction`

Nous définissons comme fonctionnalités de la plateforme open data toutes les modalités permettant à un utilisateur de la plateforme (qu'il soit producteur, intermédiaire ou réutilisateur) d'y ajouter des données ou d'accèder aux données qu'elle contient déjà. 

Pour les producteurs de données, les plateformes des deux cas leur offrent des espaces qu'ils peuvent utiliser de manière autonome pour ajouter des données. Ces espaces ont été conçu de manière à faciliter au maximum le travail d'ajout des données sur la plateforme et sont perçus comme simple d'utilisation. "(Pour ajouter des données) c’est du suivi de procédure et ça se fait sur le Web donc c’est pas compliqué. Il suffit de briefer les agents et, normalement, tous les les agents peuvent le faire, dont les agents de la communication qui n'ont pas de formation technique" (Entretien 7). 

Ainsi, lorsqu'un agent producteur de donnée ajoute des données sur la plateforme, il ne doit pas modifier ses habitudes ni acquérir de nouvelles compétences. Il doit simplement suivre les instructions. A ce propos, les concepteurs des espaces précisent : "L'objectif de cet espace, c'est d'offrir (au producteur) un processus qui soit le plus simple possible (...) et qui désilote les données mais qui ne modifie pas le mode de gestion de l'expert qui se trouve en face de l'outil" (Entretien 13)

Notons néanmoins une difficulté qui freine l'ajout de données : "renseigner correctement la donnée si ce n'est pas le cas dès l'origine" (Entretien 7). Le fait de renseigner correctement la donnée implique de fournir des informations sur les modalités de création de la donnée comme les outils utilisés, la date de production ou la fréquence de mise à jour. On nomme aussi ces informations "métadonnées". Or, ces informations sont rarement considérés comme importante par le producteur qui doit donc investir du temps pour les obtenir : "il y avait des informations mais diffuses, par exemple sur les données des bureaux de vote et les accès PMR. Sait-on quand le recensement des accès PMR a été effectué ? Il se trouve que oui. Mais la réponse au début n’était pas intuitive. Enfin, à mon niveau je ne m’étais pas posé la question et mes collègues, au niveau des services techniques ou au niveau des services population non plus. Ils n’avaient pas recensé l'information en se disant qu’elle était utile à l’extérieur". 

Finalement, du point de vue des producteurs, les interfaces remplissent leurs condititions d'interaction (simplicité, familiarité et didactiques) et les fonctionnalités de la plateforme sont effectivement utilisées. Si difficultés il y a, elles proviennent plutôt de la difficulté à renseigner des informations obligatoires. 

Du point de vue des réutilisateurs, l'utilisation de la plateforme s'avère plus difficile. Dans les deux cas, on note une certaine méfiance vis à vis des données présentes sur la plateforme et les modalités d'accès et d'utilisation de celles-ci. 

La méfiance vis à vis des données provient du fait que les réutilisateurs ont conscience que les données affichées sur la plateforme n'ont pas été produite à des fins d'ouverture et de réutilisation : "Les données sur la plateforme n’ont pas été produites pour la plateforme. Elles ont été produites en vue de faire quelque chose. Par exemple, les données de capteurs de trafic, c’est en vue de faire de la régulation. Les données emplacement de marchés, les travaux c’est en vue de faire de l’information voyageurs. Toute donnée produite qui est mis en ligne sur la plateforme n’est pas produite pour la plateforme mais dans un autre but. Pour bien interpréter les forces et les limites de cette donnée, il faut comprendre le point de vue du producteur original" (Document 1L). Ainsi, les réutilisateurs ont conscience que les plateformes n'offrent pas de données brutes et donc qu'il est assez dangeureux de se baser entièrement sur elle. 

La méfiance vis à vis des modalités d'accès provient d'un certain flou sur les licenses d'utilisation des données. Pour la plateforme du Grand Lyon, la méfiance vient du fait que la plateforme présente deux licenses atypiques en France : la license "engagée" et la license "associée", la première donne un droit de regard de la métropôle sur la réutilisation des données et  la deuxième dernière prévoyant le paiement d'une redevance pour l'accès à certaines données par l'intermédiaires d'une API (Application Programming Interface). Un développeur explique : « Une API est une surcouche qui donne des services en plus qui sont les bienvenus, mais du coup il y a des restrictions… Une API, c’est bien pour un développeur qui veut tester des usages, mais si l’on veut faire une entreprise derrière, il faut faire attention parce qu’il peut y avoir des restrictions » (Document 1L)

Pour la plateforme de la métropole grenobloise, la méfiance porte sur la license associée aux données transports, à savoir la license ODBL. Son article 4.4 spécifiait que les réutlisateurs avaient "l’obligation de repartager l’ensemble de la base dans les mêmes conditions" (Document 1G).  De fait, tout réutilisateur se trouvait dans l'obligation de mettre en open data sa base de données s'il souhaitait utiliser les données transports. Cette clause été perçue comme inconfortable par certains réutilisateurs qui, par conséquent, préferaient ne pas utiliser la plateforme et ses données. 

Finalement, du point de vue des producteurs, les plateformes ne remplissent pas certaines conditions d'interaction comme l'absence de restriction d'usage ou la garantie du caractère brut des données. Dans ce cadre, l'utilisation des fonctionnalités de la plateforme sont freinées. 

Pour certains, ces manquements contribuent à faire des plateformes des "vitrine de données"(Entretien 20) et non des points d'accès direct à ces dernières. A Lyon, le représentant d'une start-up nous a expliqué que "dans (ses) missions, on se sert des plateformes open data pour pointer à nos clients qu’il existe des données détenues par des acteurs publiques et qu’il serait intéressant pour eux et pour nous de les démarcher pour obtenir des données. Les plateformes open data, pour nous, c’est la vitrine des données, surement plus complexes et techniques, qui sont dans l’arrière cuisine et qui pourait avoir une réelle valeur dans un cadre industriel" (Entretien 20). A Grenoble, un intermédiaire en charge de la qualité des données géographiques précise que les plateformes open data sont des outils de "marketing territorial, très important pour afficher une image puis ensuite tu grattes derrière et tu vois si il y a vraiment de la donnée" (Entretien 7). 



### Evaluation du potentiel des données à partir de leur représentation

` 1. Quelle forme prennent les représentation de données ? 
  2. Quelles sont les conditions d'interactions des utilisateurs avec ces représentations ?`
` 3. Quelles sont les barrières qui empêchent la complémentarité des représentations avec les conditions d'interaction`

Pour les producteurs de données, évaluer le potentiel d'une donnée s'avère trés difficile. Lorsque ces acteurs sont chargés de produire des jeux de données qui seront ouverts, ils se trouvent en grande difficulté d'évaluer, _a priori_, le potentiel de ces données en termes de réutilisations futures. Pour Laurence Comparat, élue à la mairie de Grenoble en charge des questions d'open data et présidente d'Open Data France, cette difficulté à évaluer le potentiel est consubstantielle de l'essence de l'open data et touche aussi bien Lyon que Grenoble: "Il y a un problème intrinsèque à l’ouverture des données, c’est qu’elles sont en libre accès. Donc vous n’avez pas l’obligation que les gens qui l’utilisent vous en parle. Il y a un côté bouteille à la mer qui fait que j’ouvre les données mais "so what ?"n qu'est-ce qu'elles produisent ? Donc la question pour toutes les collectivités c'est : est-ce qu’il y a moyen de court-circuiter cet effet bouteille à la mer ?" (Entretien 17). A cause de cet effet "bouteille à la mer", les producteurs et intermédiaires de données peinent à identifier les acteurs qui réutilisent les données et donc, ne peuvent mesurer la valeur des données qu'elles libèrent. 

Du point de vue des intermédiaires, ce potentiel est également difficile à évaluer pour plusieurs raisons. La première raison relève du format dans lequel ils recoivent les données de la part des producteurs. Ces formats ne sont pas forcément lisibles par machine et donc ne sont pas intégrable dans des outils qui permettraient de mieux comprendre le contenu des données. A Grenoble, un agent explique  : "Parfois on reçoit des excels avec des couleurs ou avec d’autres choses qui ne sont pas du tout adapté à une base de données. Donc il y a toujours un long travail de lissage voir de nettoyage avant de  pouvoir l'intégrer dans une base de données". A Lyon, un agent dresse le même constat  : "souvent, les services m'envoient un fichier, et pas un tableur mais un tableau en présentation texte avec des listes de numéros. Derrière, il faut transformer les données pour les ouvrir" (Entretien 3)

Quand les formats sont lisibles par machine, les intermédiaires font face à une autre difficulté qui s'aggrave avec le temps : leur hétérogénéité et leur volumes croissants. Les intermédiaires se retrouvent avec des données de plus en plus nombreuses qui proviennent d'instruments de plus en plus divers et complexes : capteurs, compteurs communiquant, _smartphones_, applications, logiciels. 

Cette complexificiation entraine un déséquilibre entre les données disponibles et la capacité des agents à les évaluer : "On a un très haut potentiel de la production des données et une très faible capacité d’évaluation, c’est compliqué par le fait que les facteurs d’évaluation sont extrêmement nombreux et complexes" (Document 1L). A Grenoble, un agent prédit que l'essentiel des "données produites demain seront des agrégats de données personnelles, de données provenant d'objets connectés ou de capteurs. Pour les comprendre et les évaluer, il faudra alors expliciter tous les traitements de toutes ces données. L'essentiel du travail sera là" (Entretien 5) 

Pour illustrer cette complexification, nous pouvons l'exemple des données transports qui sont désormais générése par des capteurs présents sur chacun des véhicules et en temps réel : "ce sont des donnée difficiles à gérer et à interpréter, ça implique de gros volumes de donnée, de connections entre machine en temps réel, des contraines de la chaîne technique" (Document 1L).

Pour pouvoir absorber cette complexification, les intermédiaires doivent perpetuellement se former : "On aura beau avoir un référent données, il nous faut un référent donnée capable de monter en compétences sur la donnée. Quand on voit tous les volets "IoT", "Big Data", "Intelligence Artificielle". Pour tout ce qui a trait au numérique, on ne peut pas dire qu’on est compétent à un instant t, c’est une approche itérative et nécessairement continue parce qu’on a des standards qui évoluent, des types de données nouveaux"(Entretien 13). 

Or, les collectivités ne sont pas forcément armées de profils en mesure de monter perpetuellement en compétences : " Là, on a un problème de compétences dans nos collectivités. L’open data c’est nouveau, les gens ne savent pas ce que c’est et ils n’ont pas les réflexes de montée en compétences, et ils ne savent pas ce qui est de l’ordre du normal ou pas dans ce que racontent les éditeurs de logiciel. A quel point est-on armé quand on est une collectivité avec des informaticiens qui sont surtout des gestionnaires de parc et pas des spécialistes des bases de données. On est pas armé. Il y a un enjeu de montée en compétence des agents et des élus. Si on ne forme pas nos agents et agentes, ça pose problème." (Entretien 17)

Du point de revue des réutilisateurs, et du système de transformation, l'évaluation des données apparait comme une formalité et leur avis est souvent tranché : les données ne sont pas utilisables car de trop mauvaise qualité. A Lyon comme à Grenoble, de nombreuses données sont perçues comme inutiles dès le premier coup d'oeil : "Quand tu consultes les données, tu t’imagines que tu vas pouvoir faire des choses super avec ça... ils t'annoncent qu'il y a 1043 jeux de données mais il n'y a rien de qualitatif là-dedans. Pas de données venant d'acteurs privés, pas de données sur la consommation énergétique à l'échelle d'un quartier, pas des données sur les poubelles ramassées. On a pas de données sur des événements précis avec des mesures précises et non-statiques. Ce n'est pas ce n'est pas avec des données pour savoir où sont les silos à verre qu'on va générer des millions d'euros." (Entretien 14) . 

Les réutilisateurs évalue également les données en fonction de leur compatibilité avec les données avec lesquelles ils souhaitent les croiser ou avec les systèmes dans lesquels ils souhaitent injecter les données. Or, il est courant que les données incompatibles pour plusieurs raisons. Un industriel lyonnais explique : "nous ne croisons pas de l’open data avec de la donnée de systèmes industriel. La typologie, les systèmes de production de données, la fréquence de mise à jour, rien n’est pareil (...) Dans ce contexte, la donnée ouverte n'est pas encore prête à être valorisée" (Entretien 20). 

### Transformation des données grâce à des artefacts techniques

` 1. Quelle difficultés pour les données en input ? 
  2. Quelles difficultés pour les données en output ?`
` 3. Quelles difficultés dans le choix des capacités d'action ?`


Du point de vue des intermédiaires, le choix des capacités d'action à mettre en oeuvre pour transformer les données revient à choisir quel outil permettra, le plus efficacement possible, de mettre un maximum données dans un format facilitant l'ouverture des données. Il peut s'agit d'un format répondant à un standard particulier ou d'un format qui permet de représenter les données sous une forme compréhensible par tous (carte ou visualisation). 

Cette tâche s'avère difficile tant les données sont hétérogènes et non standardiées. Elles proviennent d'une myriade d'applications et de logiciels qui possèdent leur propre format de données, difficile à homogénéiser : "Le problème peut être au niveau des standards pour interconnecter. Alors, ce que fait Open Data France est un premier pas, ou les standards que nous imposent l’Etat en termes de marchés publics est aussi autre chose comme les marchés" (entretien 13). A Grenoble, le responsable de l'ouverture des données rappelle : "toute la difficulté, c’est que le spectre d’intervention, qui est tellement large. A Gières par exemple, il y avait 20-30 applications métiers et tous les excels à droite à gauche. Et si tu dis OK, je vais prendre en main un ETL et mettre les données au bon format et que tu t’en sers une fois tous les ans, ça va être compliqué parce que tu dois faire une remise en main complète de ton ETL" (Entretien 8). 

Du point de vue des réutilisateurs, la difficulté réside dans la maintenance des artefacts techniques. Soit du fait de la non-mise à jour des données ou de l'évolution constante des formats et volume, les réutilisateurs doivent en permanence maintenir les artecfacts qu'ils utilisent. Le responsable de l'ouverture des données de la métropôle grenobloise a notamment evoqué un échange avec un groupement d'industriel qui affirmait que "les données (ouvertes) ne les intéressaient pas, tant elles ne sont pas de bonne qualité. Et puis sur certaines données, en consultant d'autres sources que les metropoles, ils se sont rendus compte que les données ne serant les mêmes d'une année sur l'autre. Selon eux il n’y a pas de fiabilité, ni de pérennité. A la limite, on est prêt à payer pour que vous puissiez fournir de la donnée de qualité” (Entretien 8). 

Les producteurs et intermédiaires sont conscients de l'enjeu de la maintenance des données pour faciliter le travail des réutiliateurs. A Lyon comme à Grenoble, les responsables cherchent à mettre en oeuvre des processus à cet égard: "A Grenoble, je préfère mettre peu de jeux de données en ligne mais des données dont on est sur que le processus de libération est bon, qu’on peut mettre la donnée à jour parce qu’on a le processus et qu’on a une demande. On se concentre là-dessus" (Entretien 17). 

A Lyon, cette nouvelle exigence est présente dès la production des données : "Notre priorité est de garantir la qualité des données, qualité en continue, la structuration en continue. On va aller voir la direction de l’eau, de la voierie, des déchets. Et là, on veut être sur de la qualité et de pérennité du jeu de données. Et quand on a un expert devant nous, on veut qu’il nous assure de la qualité et de la perennité du jeu de données. Et du coup, on peut aussi valoriser, en plus de la donnée, l’expertise métier qu’il y a derrière."

Enfin, une autre difficulté réside dans l'application des règlementations relatives aux données, dont la plus importante, le Règlement pour la Protection des Données Personnelles (RGPD). Il est difficile pour les réutilisateurs de savoir quelles sont les dispositions réglèmentaires qu'ils doivent prendre en compte pour transformer les données dans la mesure où le positionnement des données dans tel ou tel domaine est difficile. Qu'est-ce qui donne le caractère personnel à des données ? le caractère public ou privé ? Ces questions s'avèrent complexe et peuvent bloquer l'utilisation des données : "il y a des cadres mais c’est dans l’évolution que ça pose problème. On avait open data, maintenant RGPD, demain l'Internet des Objects avec les données personnelles...Et une grosse problèmatique liées à cette évolution, c'est que la frontière entre public et privé est flou. Aujourd’hui, on a des données de caractère d’intérêt général, qui sont captées par des acteurs privés. Mais on peut aussi avoir des données d’intérêt général, captées par les collectivités mais qui intéresse les acteurs privés."




### Création d'un cadre cognitif partagé entre les systèmes pour les coordonner

` 1. Quelles sont les activités menées pour créer ce cadre cognitif ? 
  2. Quelle est la position par rapport à la plateforme ?`
` 3. Comment ce cadre permet-il de coordonner les systèmes ?`

Nous définissons un cadre cognitif partagé comme un ensemble d'éléments permettant aux agents d'acquérir une compréhension commune d'un phénomène et des pratiques qui le supporte, à savoir dans notre étude : l'usage de l'open data. 

Les métropôles de Grenoble et de Lyon apparaissent dans les données récoltées comme fortement impliquées dans la construction d'élements de compréhension et de pratique commune. Dans la délibération à l'origine de la démarche d'ouverture de la métropôle Grenoble-Alpes, on trouve mentionné l'importance de développer  des "interactions avec Ie réseau Open Data France et les associations nationales et internationales sur l'Open data pour la déﬁnition de référentiels communs" (Document 2G). Par "référentiel commun", il est ici fait référence aussi bien à des standards de données qu'à l'instauration de pratiques communes pour la production l'édition et la transformation des données. 

On trouve ce même engagement à la métropôle Lyon qui souhaite faire de son territoire un "archipel, où nous serions au centre pour créer des ponts entre les acteurs de la donnée, entre réutilisateurs, entre producteurs, entre producteurs et réutilisateurs et avec le reste de la sphère qui sont les associations, les chercheurs, le monde académique au niveau régional et national" (Entretien 13). 

Pour créer ce cadre cognitif, les deux métropôles se sont engagées dans un travail dit "d'évangélisation", une connotation religieuse qui trouve son sens quand il est question de vouloir rassembler des acteurs autour d'une même conception des choses.A Grenoble : "l'open data, c'est en premier lieu des tâches de fonds, aller voir chaque commune pour que ça prenne doucement. D'où l’importance (des chefs de projets open data) pour soutenir, l’animer, aider les gens. Ols peuvent s’appuyer aussi sur Open Data France mais ils font déjà pas mal de travail d’évangélisation par eux-mêmes. Et après, c’est l’effet boule de neige qui va devenir intéressant" (Entretien 7). 

A Lyon, cette évangélisation est portée par un laboratoire d'innovation urbaine, le Tuba. Au lieu d'évangélisation les membres de ce laboratoire préfère parler de "médiation" Un chargé d'expérimentation explique : "c'est très important de faire de la médiation car on est sur des problématiques très complexes quand tu parles d'open data à un représentant d'un quartier de la ville de Lyon il est un peu perdu et il a besoin de médiation sur le sujet. On fait de la médiation pour se faire comprendre auprès des gens avec lesquels on va mener nos expérimentations sur les nouveaux services urbains à partir des données. Sans cette médiation on arrivera jamais à transformer la ville comme on veut le faire" (Entretien 14)

A la suite de cette évangélisation, il est question pour les métropôles de fédérer les acteurs de son territoire autour de pratiques communes. C'est par la pratique qu'elles comptent favoriser le plus l'usage de l'open data. 

Du côté des producteurs, les métropoles accompagnent toutes les communes de leur territoire pour les rendre autonomes. Pour cela, elles mettent en oeuvre des process et bonnes pratiques. A Lyon sont organisées des réunions "sur le structuration des données, sur comment on définit une structure commune de données. C’est là qu’on interagit en direct  avec les communes, avec la métropôle. C’est là qu’on a pu échanger sur nos différents points de vue autour des données qu’on a tous. Sachant qu’on a certaines communes qui veulent aller plus loin que la structuration. Ca dépend des moyens qu’on a pour arriver ensuite à produire des données". A Grenoble, il est question d'organiser des ateliers "dans une commune pour leur demander quels sont les jeux de données qu’ils souhaitent libérer. On a liste les jeux de données à libérer puis on les accompagne derrière pour sortir les données en open data" (Entretien 8) 

Du côté des réutilisateurs, les métropoles finance l'animation de groupes de réutilisateurs. Cette animation passe notamment par l'organisation d'évènements au cours desquels elles accompagnent et aident à structurer des projets de réutilisation de données. Ces évènements sont tous les deux portés par des laboratoires d'innovation : la Péniche à Grenoble et le Tuba à Lyon. A Lyon, leur objectif est d'arriver à "écrire des protocoles pour mener des projets avec l'open data, ça peut être une méthodologie de projet mais ça peut être aussi un guide d'entretien ou des choses plus loufoques avec des méthodologies un peu plus innovantes" (Entretien 14)

Dans l'évangélisation et la mise en place de pratiques communes, tous les acteurs impliqués dans l'usage de l'open data font face à une difficulté : le manque d'un cadre stratégique clair. Les objectifs et les moyens alloué à l'ouverture, l'édition et la transformation ne sont pas clairs, pour ne pas dire inexistant : " Oui on a des difficultés à articuler une stratégie mais on se met dans l'optique d'en créer une stratégie. Ce qu’il faut rappeler c’est qu'entre 2015 et 2017, ils ont fait comme ils ont pu. Et ce n'est que depuis mon retour, on s’est dit qu’on allait cadrer les choses, se donner une ligne de conduite pour savoir ce qu’on fait" (Entretien 8). 

A Lyon, si ce cadre existe par l'intermédiaire d'un document cadre sur la stratégie Smart city de la métropole lyonnaise, c'est la mise en oeuvre au delà des déclarations d'intention stratégique qui se trouvent bloqué, à l'image du Tuba. Alors que celui-ci a été créée en 2012 à la base pour faciliter la réutilisation et l’aggrégation des données, ils n'ont "jamais vu un jeu de données transiter par chez (eux)" (Entretien 14). "Les partenaires ne voulait pas partager des données ou alors sur des domaines très précis donc c'était du partage et non de l'ouverture. Finalement sur la démarche Open Data on est un peu frustré parce que les partenaires qui ont rejoint le programme ne l'ont pas fait pour ouvrir leur donner mais ils l'ont plus fait dans une dynamique politique" (Entretien 14)

### Institutionnalisation de l'usage des données

` 1. Quelles sont les activités menées pour créer ce cadre cognitif ? 
  2. Quelle est la position par rapport à la plateforme ?`
` 3. Comment ce cadre permet-il de coordonner les systèmes ?`

L’institutionnalisation est ici entendue comme " l’intégration de l'enjeu de gouvernance de la donnée au sein des organisations " (Courmont, 2015, p.328). 

Les métropoles de Lyon et Grenoble ont toutes deux initié la mise en oeuvre, rencontrant de nombreuses difficultés : "Au Grand Lyon, c’est assez compliqué. Il y a avait une forme de gouvernance des données sur les données géographiques, avec des instances de décisions et une certaine forme d’organisation. C’était en place depuis les années 80, 90. (...) plus récemment, c'est compliqué du fait des grandes reconfigurations au sein de l’institution : en 2015, la communauté urbaine de Lyon est devenue métropôle et a fusionné avec le département du Rhône, ce qui a conduit a pas mal de réorganisations de l’administration. Tout le process autour de l’action et du numérique s’est retrouvé au milieu de ce chamboulement, avec les données" (Entretien 2). 

A Grenoble, la mise en place d'une gouvernance des données au sein des organisatiosn est en encore au stade de l'idée : "Pour nous, une vraie barrière, c'est de savoir quelle organisation on met en oeuvre pour faire ça. Aujourd’hui, on fait juste comme on peut. Pour cela, il faut qu’on béneficie d'un minimum d’accompagnement pour avoir apporter quelque chose en plus à l'écosystèlme" (Entretien 8). 

Pour les producteurs, la première chose sur laquelle ils trébuchent est l'architecture des système d'information, souvent sectorialisée, qui rend difficile la production de l'open data : "La mise en place d'une organisation dépend de la structuration du système d'information qui peut être très sectorialisée par métier ou beaucoup plus transverse, avec un avantage pour la deuxième. Ca dépend des organisations et ça joue beaucoup sur ce que tu peux faire avec les données" (Entretien 2). 

En termes d'architecture, les producteurs et intermédiaires se heurtent également à la "démarche applicative" qui prévaut dans la façon de l'envisager. Ce mode de gestion des systèmes d'information veut qu'à chaque besoin de logiciel, on créé une nouvelle base de donnée et qu'on ne pense pas à aller récupérer les données déjà présentes : "on a vraiment cette dimension qui est du au fait qu’on adjoint à chaque besoin une application. Et pour que les services se mettent en commun et créer une base commune, il faudra un certain temps. Et du coup, on se retrouve avec des agents et des prestataires qui ne gèrent que le logiciel et qui ne font pas le lien avec la donnée. Il faut comprendre que quand j’identifie un besoin, il est beaucoup plus facile de faire un cahier des charges en isolant tout ce qui a trait à ce logiciel parce que derrière les éditeurs vont répondre avec leurs outils propre sur chacun des points listés. Alors que si on créé une base de donnée communes et qu’on demande au prestataire de s’y connecter, ça ne va pas plaire et le prestataire va dire que c’est au risque et péril du commanditaire parce qu’il n’aura pas la main sur les données." (Entretien 8) 

Parmi les autres freins à l'institutionnalisation, les acteurs pointent l'incompatibilité des cultures organisationnelles avec l'usage de l'open data. Pour les organisations publiques, l'incompatibilité vient du fait que l'open data porte l'accent sur la transversalité, la mise en lumière des métiers et de leur expertise, ce qui "boulverse l’organisation parce que vous désilotez. L’accès à la donnée est l’occasion d’encourager le partage et le savoir. On va décrire ensemble les méta-données on va décrire les données et le métier qu’elle rend visible. Il faut essayer de minimiser ce bouleversement sous peine de voir les projets rejetés" (Entretien 13). 

Pour d'autres organisations, la difficulté réside dans le fait que l'usage des données ouvertes n'a pas encore fait ses preuves en termes de résultat concrets et à court-terme : "De mon point de vue les entreprises freinent des quatre fers pour ne pas avoir à libérer leur données. Ils n'ont pas entendu parler de projet concrets avec les données ouvertes donc ils ne les utiliseront et n'ouvriront pas les leurs non plus. A la limite, ils peuvent faire de l'Open Data washing en  produisent quelques graphes ridicules"(Entretien 14). Pour les petites collectivités, un constat similaire est établi : "Et l’open data ne fait pas partie du mode de fonctionnement de la commune. Ca parait logique que ca ne rentre pas dans les priorités. Le but d’une collectivité, c’est déjà de rendre des services à ses administrés au quotidien et pour les communes, la data n’est pas encore un enjeu crucial à ce niveau là. Alors que pour le travail des métropôles, c’est essentiel"(Entretien 6)

En termes de culture organisationnelle, la difficulté vient aussi du fait que l'open data, autant dans sa production que dans sa réutilisation sont perçues comme comportant de nombreux risques. Or, certaines cultures organisationnelles présente une aversion au risque.

En libérant des données, certaines organisations considèrent qu'elles prennent le risque de voir leurs dysfonctionnements mis à jour. Ce qui metterait à mal une certaine un trait culturel rattaché à la discrétion : "prenons l'exemple des opérateurs dans le cadre d’une délégation du service public comme Vinci, Eiffage ou Véolia, etc. Ces acteurs‐là n’ont pas du tout envie de publier ces données en OD parce qu'on peut observer ce qu’ils font par exemple si le tram a du retard tout le temps, ils n’aiment pas du tout donner de l’information qui risquerait de leur retomber sur la tête, parce que quelque part c’est donner à observer la qualité de service qu’ils devraient assurer" (Document 1L)

Encore, l'open data est-il perçu comme un facteur pouvant fragiliser les avantages concurrentiels des organisations et la maitrise de leur stratégie : "Pour des raisons de pouvoirs, certaines direction au sein de la métropole n’ont pas le même rapport à la diffusion. Et j’imagine que c’est pareil dans les autres organisations. Par exemple on peut avoir la direction de l’eau qui a sa propre stratégie en termes de délegation de services publics et qui ne voit pas l’intérêt de mettre à disposition ces données, car ils ne veulent pas perdre la maitrise de leurs stratégies" (Entretien 2)






















- PhD Working Book (6) - p.46 - Utilisation de la cartographie de données pour organiser les données 
- PhD Working Book (7) - Idées sur la procédure de codage et infos à extraire


**Grenoble - Barrières socio-techniques rencontrées**

##### Les barrières relatives aux interactions entre les agents et les technologies 

**Dans le sous-système des réutilisateurs de données**
En synthèse du tableau ci-dessous, nous pouvons affirmer que dans le sous-système des réutilisateurs de données, les interactions entre les agents et les technologies sont freinées par deux aspects : 

- un manque de qualité et de pérennité des données ouvertes

- un manque de ressources et de compétences techniques pour travailler les données ouvertes 

Le premier point est mis en avant lors des premières opérations effectuées par les réutilisateurs. Avant d’utiliser les données, ils évaluent la qualité du jeu de donnée, c’est à dire sa fiabilité, ainsi que sa pérennité. Ces mesures permettent de s’assurer que le service créé ne sera pas obsolète rapidement du fait de l’absence de mise à jour des données ou de sa disparition. En l’occurence, si les données ne sont pas de bonnes qualités, alors les réutilisateurs n’entament pas le travail de la donnée. 

Le deuxième point est quant à lui relatif aux compétences ou ressources détenues par les réutilisateurs. Dans les équipes ne possédant pas de profils techniques (développeur ou data-scientist) pour prendre en charge la modification des jeux de données et le développement des services digitaux, le processus de conception du service atteint rapidemment ses limites. 

**Dans le sous-système des fournisseurs de données**  
En synthèse du tableau ci-dessous, nous pouvons affirmer que dans le sous-système des produteurs de données, les interactions entre les agents et les technologies sont freinées par : 

- la complexité du SI sous-jacent à la production de données 

- un manque de ressources et de compétences techniques pour produire les données ouvertes
 
- l’absence de certification des outils hors SI permettant de produire des données ouvertes 

La barrière de la complexité du SI explique qu’il soit difficile de passer directement des données métiers générées par les applications à des données ouvertes. Chaque application possédant son propre format de données, il faut que les fournisseurs déploient des ressources à la conversion des format de données métiers en format de données ouvertes. 

Le manque de ressources et de compétences techniques sur les aspects data des agents est à l’origine d’un manque d’implication et de compréhension qui permettrait aux fournisseurs de penser la production de la donnée ouverte dès la collecte de la donnée. L’exemple type évoqué dans les entretiens concerne les phases de négociations avec les éditeurs de logiciels : les agents ne possèdent pas les compétences pour discuter des composants d’un logiciel qui permettrait d’exporter les données de leurs solutions dans un format ouvert. 

Enfin, le dernier point renvoie aux activités de production de jeux de données ouvert non pas à partir des applications métiers du SI mais à partir d’autres données déjà disponibles. Les fournisseurs sont ici bloqué par le fait que les outils libres qu’ils pourraient utiliser pour créer de la donnée ne sont pas certifiés. Ainsi, il est impossible de savoir pour le fournisseur si la donnée qu’il produit est fiable. 

**Dans le sous-système des intermédaires de données** 
En synthèse du tableau ci-dessous, nous pouvons affirmer que dans le sous-système des intermédiaires de données, les interactions entre les agents et les technologies sont freinées par : 

- la trés grande hétérogénéité des données qui rend difficile le travail de normalisation et de standardisation des jeux de données  

- manque de renseignement sur les données à ouvrir

La barrière de l’hétérogénéité provient du fait que le périmètre des données à ouvrir est extrêmement large. De ce fait, les intermédiaires sont en possession de données de multiples sources, avec leur prore modèle et standard. Pour normaliser ces données et les rendre conforme aux standards, un long travail est nécessaire. Ce travail nécessite d’autant plus d’investissement que les standards et les normes s’actualisent au fur et à mesure. 

Le manque de renseignement sur les données à ouvrir rend difficile le travail de l’intermédiaire dans la mesure où il impacte le travail de compréhension et de qualification du jeu de données. Avec peu de renseignements, il sera par exemple difficile de classer le jeu de donnée sur une plateforme open data. 


##### Les barrières relatives aux interactions entre agents de l’open data work 

**Entre fournisseurs et intermédiaires**
On remarque que la majorité des barrières freinant les interactions entre les fournisseurs et les intermédiaires de l’open data work est de l’ordre de la compréhension mutuelle. La gestion de la donnée est mal comprise, tout comme la feuille de route de la démarche open data et les apports finaux de la démarche. On rajoutera la mention de l’absence d’un vocabulaire commun qui vient confirmer qu’il manque un moyen permettant de mieux communiquer autour de la donnée entre les fournisseurs et les intermédiaires. 

- Isolement de l’intermédiaire au sein des organisations productrices 
- Tarification excessive de la part des éditeurs de logiciels 
- Gestion ‘applicative’ de la donnée rend difficile le travail de mise en commun de la donnée
- Manque de lisibilité sur la gestion de la donnée
- Absence d’un vocabulaire commun pour réduire la complexité
- Absence d’un circuit de validation de la donnée
- Difficulté à atteindre un seuil de donnée suffisant pour lancer la démarche 
- Manque de ressources pour accompagner les fournisseurs 
- Manque de ressources pour suivre l’accompagnement des intermédiaires
- Manque de lisibilité de la part des intermédiaires sur la feuille de route de la démarche 
- Manque de lisibilité sur les apports de la démarche open data (effet bouteille à la mer)
- Manque de compétences techniques des agents fournisseurs de la donnée
- Cloisonnage organisationnel 

**Entre fournisseurs et réutilisateur**
Les interactions entre fournisseurs et réutilisateurs sont aussi freinées par un manque de compréhension de la part des réutilisateurs à propos du travail des fournisseurs. Il leur manque des informations permettant de comprendre la nature et les caractéristiques de la donnée ouverte. Aussi notons nous que les fournisseurs ne s’impliquent pas dans la co-production des réutilisations. 

- Manque de lisibité sur la gestion de la donnée
- Manque d’implication des fournisseurs dans la co-production des réutilisations 


**Entre intermédiaires et réutilisateurs**
Les interactions entre fournisseurs et réutilisateurs sont aussi freinées par le manque de lisibilité sur la démarche open data mais aussi par la difficulté d’obtenir des jeux de données pourtant disponibles. Enfin, on notera des difficultés quant aux conseils prodigués par les intermédiaires de l’open data à propos du modèle économique des réutilisations. 

- Manque de lisibilité sur la démarche open data
- Conseils sur le modèle économique diffus
- Difficulté à obtenir suffisamment de données pour la réutilisation  

![cartographie](http://opendatatales.com/wp-content/uploads/2020/03/V4_Plan-Etude-de-cas-Grenoble_SansRetoursCDP_2019-04-29-Google-Docs.png)
##### Figure : cartographie des barrières sociales 


**Page 4**

Lorem ipsum dolor sit amet, facilis propriae delicata est eu, at cum periculis complectitur, his cu tale tritani eligendi. In pri affert fabellas, qui eu congue oblique. Pri cu unum solet consul, ius ex soleat debitis. Aliquam graecis pertinax usu et, ad clita nostrud eam. Et vix facete sanctus, omnis scaevola ea cum. Vis malorum similique at, omnis ullum feugiat nec at, est movet iriure scaevola te. Et audire fastidii molestiae duo.

Vel possim sapientem concludaturque no, sed ei cibo tollit repudiare, ius laoreet docendi scribentur te. Has id erroribus contentiones. Nulla oportere quo et, wisi tation mentitum ne mel. Et cum modo rationibus, no vocibus nusquam vis, ad sed pertinacia instructior. Aperiam principes vix ut.

Altera laoreet intellegam an has, ubique populo consequat an cum, sint esse inimicus ne nam. Mel et vocibus nominavi phaedrum. Pro utroque ponderum pericula at, pri et facilisis eloquentiam. Eam brute malorum cu, ex nihil detraxit his, ex alienum fierent principes sit.

Vituperata ullamcorper at sit. Eam ut consul contentiones, pri an timeam erroribus. No fugit nihil atomorum per, vim adhuc atomorum ei. Te autem velit honestatis per, iisque aliquid tacimates et cum.

Ius sanctus facilisi vituperata ei, eius ipsum consul ne vel. No per ocurreret corrumpit consequuntur, postea commodo assentior no pri, quo id dicat homero maiorum. Cu dicam tation usu. No quo forensibus disputando, feugiat perpetua vituperata qui cu.

Ridens moderatius mel ut. Sed quot probo temporibus ei, quo tale adhuc doctus ne. Ne nam probo dicit. In pro equidem iracundia, nisl error ludus te nam, an vim brute delenit. Diceret noluisse incorrupte ne nam, et sed utamur sanctus assentior, dolore causae id pri. Copiosae consequat ius id, elitr gloriatur ius ad. Te choro molestiae qui.

Sed no tota ipsum ancillae, veri ullum inermis pro id, quando scripta has ne. Pro electram complectitur ei. Te mei insolens dignissim, et tota soluta omnesque nam, sale oratio dolores te sea. Ignota postulant usu an. Oblique voluptua mei cu, est instructior necessitatibus cu. Everti mollis quo ea, oporteat deterruisset eu vel.

**Page 5**

Lorem ipsum dolor sit amet, facilis propriae delicata est eu, at cum periculis complectitur, his cu tale tritani eligendi. In pri affert fabellas, qui eu congue oblique. Pri cu unum solet consul, ius ex soleat debitis. Aliquam graecis pertinax usu et, ad clita nostrud eam. Et vix facete sanctus, omnis scaevola ea cum. Vis malorum similique at, omnis ullum feugiat nec at, est movet iriure scaevola te. Et audire fastidii molestiae duo.

Vel possim sapientem concludaturque no, sed ei cibo tollit repudiare, ius laoreet docendi scribentur te. Has id erroribus contentiones. Nulla oportere quo et, wisi tation mentitum ne mel. Et cum modo rationibus, no vocibus nusquam vis, ad sed pertinacia instructior. Aperiam principes vix ut.

Altera laoreet intellegam an has, ubique populo consequat an cum, sint esse inimicus ne nam. Mel et vocibus nominavi phaedrum. Pro utroque ponderum pericula at, pri et facilisis eloquentiam. Eam brute malorum cu, ex nihil detraxit his, ex alienum fierent principes sit.

Vituperata ullamcorper at sit. Eam ut consul contentiones, pri an timeam erroribus. No fugit nihil atomorum per, vim adhuc atomorum ei. Te autem velit honestatis per, iisque aliquid tacimates et cum.

Ius sanctus facilisi vituperata ei, eius ipsum consul ne vel. No per ocurreret corrumpit consequuntur, postea commodo assentior no pri, quo id dicat homero maiorum. Cu dicam tation usu. No quo forensibus disputando, feugiat perpetua vituperata qui cu.

Ridens moderatius mel ut. Sed quot probo temporibus ei, quo tale adhuc doctus ne. Ne nam probo dicit. In pro equidem iracundia, nisl error ludus te nam, an vim brute delenit. Diceret noluisse incorrupte ne nam, et sed utamur sanctus assentior, dolore causae id pri. Copiosae consequat ius id, elitr gloriatur ius ad. Te choro molestiae qui.

Sed no tota ipsum ancillae, veri ullum inermis pro id, quando scripta has ne. Pro electram complectitur ei. Te mei insolens dignissim, et tota soluta omnesque nam, sale oratio dolores te sea. Ignota postulant usu an. Oblique voluptua mei cu, est instructior necessitatibus cu. Everti mollis quo ea, oporteat deterruisset eu vel.

**Page 6**

Lorem ipsum dolor sit amet, facilis propriae delicata est eu, at cum periculis complectitur, his cu tale tritani eligendi. In pri affert fabellas, qui eu congue oblique. Pri cu unum solet consul, ius ex soleat debitis. Aliquam graecis pertinax usu et, ad clita nostrud eam. Et vix facete sanctus, omnis scaevola ea cum. Vis malorum similique at, omnis ullum feugiat nec at, est movet iriure scaevola te. Et audire fastidii molestiae duo.

Vel possim sapientem concludaturque no, sed ei cibo tollit repudiare, ius laoreet docendi scribentur te. Has id erroribus contentiones. Nulla oportere quo et, wisi tation mentitum ne mel. Et cum modo rationibus, no vocibus nusquam vis, ad sed pertinacia instructior. Aperiam principes vix ut.

Altera laoreet intellegam an has, ubique populo consequat an cum, sint esse inimicus ne nam. Mel et vocibus nominavi phaedrum. Pro utroque ponderum pericula at, pri et facilisis eloquentiam. Eam brute malorum cu, ex nihil detraxit his, ex alienum fierent principes sit.

Vituperata ullamcorper at sit. Eam ut consul contentiones, pri an timeam erroribus. No fugit nihil atomorum per, vim adhuc atomorum ei. Te autem velit honestatis per, iisque aliquid tacimates et cum.

Ius sanctus facilisi vituperata ei, eius ipsum consul ne vel. No per ocurreret corrumpit consequuntur, postea commodo assentior no pri, quo id dicat homero maiorum. Cu dicam tation usu. No quo forensibus disputando, feugiat perpetua vituperata qui cu.

Ridens moderatius mel ut. Sed quot probo temporibus ei, quo tale adhuc doctus ne. Ne nam probo dicit. In pro equidem iracundia, nisl error ludus te nam, an vim brute delenit. Diceret noluisse incorrupte ne nam, et sed utamur sanctus assentior, dolore causae id pri. Copiosae consequat ius id, elitr gloriatur ius ad. Te choro molestiae qui.

Sed no tota ipsum ancillae, veri ullum inermis pro id, quando scripta has ne. Pro electram complectitur ei. Te mei insolens dignissim, et tota soluta omnesque nam, sale oratio dolores te sea. Ignota postulant usu an. Oblique voluptua mei cu, est instructior necessitatibus cu. Everti mollis quo ea, oporteat deterruisset eu vel.

**Page 7**

Lorem ipsum dolor sit amet, facilis propriae delicata est eu, at cum periculis complectitur, his cu tale tritani eligendi. In pri affert fabellas, qui eu congue oblique. Pri cu unum solet consul, ius ex soleat debitis. Aliquam graecis pertinax usu et, ad clita nostrud eam. Et vix facete sanctus, omnis scaevola ea cum. Vis malorum similique at, omnis ullum feugiat nec at, est movet iriure scaevola te. Et audire fastidii molestiae duo.

Vel possim sapientem concludaturque no, sed ei cibo tollit repudiare, ius laoreet docendi scribentur te. Has id erroribus contentiones. Nulla oportere quo et, wisi tation mentitum ne mel. Et cum modo rationibus, no vocibus nusquam vis, ad sed pertinacia instructior. Aperiam principes vix ut.

Altera laoreet intellegam an has, ubique populo consequat an cum, sint esse inimicus ne nam. Mel et vocibus nominavi phaedrum. Pro utroque ponderum pericula at, pri et facilisis eloquentiam. Eam brute malorum cu, ex nihil detraxit his, ex alienum fierent principes sit.

Vituperata ullamcorper at sit. Eam ut consul contentiones, pri an timeam erroribus. No fugit nihil atomorum per, vim adhuc atomorum ei. Te autem velit honestatis per, iisque aliquid tacimates et cum.

Ius sanctus facilisi vituperata ei, eius ipsum consul ne vel. No per ocurreret corrumpit consequuntur, postea commodo assentior no pri, quo id dicat homero maiorum. Cu dicam tation usu. No quo forensibus disputando, feugiat perpetua vituperata qui cu.

Ridens moderatius mel ut. Sed quot probo temporibus ei, quo tale adhuc doctus ne. Ne nam probo dicit. In pro equidem iracundia, nisl error ludus te nam, an vim brute delenit. Diceret noluisse incorrupte ne nam, et sed utamur sanctus assentior, dolore causae id pri. Copiosae consequat ius id, elitr gloriatur ius ad. Te choro molestiae qui.

Sed no tota ipsum ancillae, veri ullum inermis pro id, quando scripta has ne. Pro electram complectitur ei. Te mei insolens dignissim, et tota soluta omnesque nam, sale oratio dolores te sea. Ignota postulant usu an. Oblique voluptua mei cu, est instructior necessitatibus cu. Everti mollis quo ea, oporteat deterruisset eu vel.

**Page 8**

Lorem ipsum dolor sit amet, facilis propriae delicata est eu, at cum periculis complectitur, his cu tale tritani eligendi. In pri affert fabellas, qui eu congue oblique. Pri cu unum solet consul, ius ex soleat debitis. Aliquam graecis pertinax usu et, ad clita nostrud eam. Et vix facete sanctus, omnis scaevola ea cum. Vis malorum similique at, omnis ullum feugiat nec at, est movet iriure scaevola te. Et audire fastidii molestiae duo.

Vel possim sapientem concludaturque no, sed ei cibo tollit repudiare, ius laoreet docendi scribentur te. Has id erroribus contentiones. Nulla oportere quo et, wisi tation mentitum ne mel. Et cum modo rationibus, no vocibus nusquam vis, ad sed pertinacia instructior. Aperiam principes vix ut.

Altera laoreet intellegam an has, ubique populo consequat an cum, sint esse inimicus ne nam. Mel et vocibus nominavi phaedrum. Pro utroque ponderum pericula at, pri et facilisis eloquentiam. Eam brute malorum cu, ex nihil detraxit his, ex alienum fierent principes sit.

Vituperata ullamcorper at sit. Eam ut consul contentiones, pri an timeam erroribus. No fugit nihil atomorum per, vim adhuc atomorum ei. Te autem velit honestatis per, iisque aliquid tacimates et cum.

Ius sanctus facilisi vituperata ei, eius ipsum consul ne vel. No per ocurreret corrumpit consequuntur, postea commodo assentior no pri, quo id dicat homero maiorum. Cu dicam tation usu. No quo forensibus disputando, feugiat perpetua vituperata qui cu.

Ridens moderatius mel ut. Sed quot probo temporibus ei, quo tale adhuc doctus ne. Ne nam probo dicit. In pro equidem iracundia, nisl error ludus te nam, an vim brute delenit. Diceret noluisse incorrupte ne nam, et sed utamur sanctus assentior, dolore causae id pri. Copiosae consequat ius id, elitr gloriatur ius ad. Te choro molestiae qui.

Sed no tota ipsum ancillae, veri ullum inermis pro id, quando scripta has ne. Pro electram complectitur ei. Te mei insolens dignissim, et tota soluta omnesque nam, sale oratio dolores te sea. Ignota postulant usu an. Oblique voluptua mei cu, est instructior necessitatibus cu. Everti mollis quo ea, oporteat deterruisset eu vel.

**Page 9**

Lorem ipsum dolor sit amet, facilis propriae delicata est eu, at cum periculis complectitur, his cu tale tritani eligendi. In pri affert fabellas, qui eu congue oblique. Pri cu unum solet consul, ius ex soleat debitis. Aliquam graecis pertinax usu et, ad clita nostrud eam. Et vix facete sanctus, omnis scaevola ea cum. Vis malorum similique at, omnis ullum feugiat nec at, est movet iriure scaevola te. Et audire fastidii molestiae duo.

Vel possim sapientem concludaturque no, sed ei cibo tollit repudiare, ius laoreet docendi scribentur te. Has id erroribus contentiones. Nulla oportere quo et, wisi tation mentitum ne mel. Et cum modo rationibus, no vocibus nusquam vis, ad sed pertinacia instructior. Aperiam principes vix ut.

Altera laoreet intellegam an has, ubique populo consequat an cum, sint esse inimicus ne nam. Mel et vocibus nominavi phaedrum. Pro utroque ponderum pericula at, pri et facilisis eloquentiam. Eam brute malorum cu, ex nihil detraxit his, ex alienum fierent principes sit.

Vituperata ullamcorper at sit. Eam ut consul contentiones, pri an timeam erroribus. No fugit nihil atomorum per, vim adhuc atomorum ei. Te autem velit honestatis per, iisque aliquid tacimates et cum.

Ius sanctus facilisi vituperata ei, eius ipsum consul ne vel. No per ocurreret corrumpit consequuntur, postea commodo assentior no pri, quo id dicat homero maiorum. Cu dicam tation usu. No quo forensibus disputando, feugiat perpetua vituperata qui cu.

Ridens moderatius mel ut. Sed quot probo temporibus ei, quo tale adhuc doctus ne. Ne nam probo dicit. In pro equidem iracundia, nisl error ludus te nam, an vim brute delenit. Diceret noluisse incorrupte ne nam, et sed utamur sanctus assentior, dolore causae id pri. Copiosae consequat ius id, elitr gloriatur ius ad. Te choro molestiae qui.

Sed no tota ipsum ancillae, veri ullum inermis pro id, quando scripta has ne. Pro electram complectitur ei. Te mei insolens dignissim, et tota soluta omnesque nam, sale oratio dolores te sea. Ignota postulant usu an. Oblique voluptua mei cu, est instructior necessitatibus cu. Everti mollis quo ea, oporteat deterruisset eu vel.

**Page 10**

Lorem ipsum dolor sit amet, facilis propriae delicata est eu, at cum periculis complectitur, his cu tale tritani eligendi. In pri affert fabellas, qui eu congue oblique. Pri cu unum solet consul, ius ex soleat debitis. Aliquam graecis pertinax usu et, ad clita nostrud eam. Et vix facete sanctus, omnis scaevola ea cum. Vis malorum similique at, omnis ullum feugiat nec at, est movet iriure scaevola te. Et audire fastidii molestiae duo.

Vel possim sapientem concludaturque no, sed ei cibo tollit repudiare, ius laoreet docendi scribentur te. Has id erroribus contentiones. Nulla oportere quo et, wisi tation mentitum ne mel. Et cum modo rationibus, no vocibus nusquam vis, ad sed pertinacia instructior. Aperiam principes vix ut.

Altera laoreet intellegam an has, ubique populo consequat an cum, sint esse inimicus ne nam. Mel et vocibus nominavi phaedrum. Pro utroque ponderum pericula at, pri et facilisis eloquentiam. Eam brute malorum cu, ex nihil detraxit his, ex alienum fierent principes sit.

Vituperata ullamcorper at sit. Eam ut consul contentiones, pri an timeam erroribus. No fugit nihil atomorum per, vim adhuc atomorum ei. Te autem velit honestatis per, iisque aliquid tacimates et cum.

Ius sanctus facilisi vituperata ei, eius ipsum consul ne vel. No per ocurreret corrumpit consequuntur, postea commodo assentior no pri, quo id dicat homero maiorum. Cu dicam tation usu. No quo forensibus disputando, feugiat perpetua vituperata qui cu.

Ridens moderatius mel ut. Sed quot probo temporibus ei, quo tale adhuc doctus ne. Ne nam probo dicit. In pro equidem iracundia, nisl error ludus te nam, an vim brute delenit. Diceret noluisse incorrupte ne nam, et sed utamur sanctus assentior, dolore causae id pri. Copiosae consequat ius id, elitr gloriatur ius ad. Te choro molestiae qui.

Sed no tota ipsum ancillae, veri ullum inermis pro id, quando scripta has ne. Pro electram complectitur ei. Te mei insolens dignissim, et tota soluta omnesque nam, sale oratio dolores te sea. Ignota postulant usu an. Oblique voluptua mei cu, est instructior necessitatibus cu. Everti mollis quo ea, oporteat deterruisset eu vel.
