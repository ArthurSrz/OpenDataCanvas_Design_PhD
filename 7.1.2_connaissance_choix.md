## 7.1.2 Choix d'une stratégie d'évaluation 

### Choix d'une stratégie d'évaluation pour la version 0 du prototype

Dans cette partie, il est question de choisir une stratégie d'évaluation en reportant dans le Framework de Sélection des Stratégies d'Evaluation en Design Science Research (Venable et al., 2012, p.11) les 7 critères de la version 0 du prototype de l'Open Data Canvas décrits dans [la partie précédente](7.1.1_connaissance_evaluation.md). Suite à ce report d'information, le framework permet de déduire la stratégie d'évaluation adaptée. 

Dans cette partie, je présente le framework de sélection de la stratégie d'évaluation de la version 0 du prototype (tableau ci-dessou) et en déduie le choix de la stratégie d'évaluation.


<table>
    <thead>
        <tr>
            <th colspan=2 rowspan=2>Framework de Selection des Stratégies d'Evaluation</th>
            <th>Ex ante (avant le prototypage) </th>
            <th>Ex post (après le prototypage) </th>
        </tr>
    </thead>
    <tbody>
      <tr>
            <td></td>
            <td></td>
            <td><ul><li>[X] Evaluation formative</li><li>[X] Cout moins élevé</li><li>[X] Plus rapide</li><li>[X] Evaluation du design, d'un protoype partiel ou complet</li><li>[ ] Moins de risque pour les participants durant l'évaluation</li><li>[ ] Risque plus élevé de faux positifs</li></ul></td>
            <td><ul><li>[ ] Evaluation sommative</li><li>[ ] Cout plus élevé</li><li>[ ] Moins rapide</li><li>[ ] Evaluation des instances</li><li>[ ] Plus de risques pour les participants durant l'évaluation</li><li>[ ] Risque moins élevé de faux positifs</li></ul></td>
        </tr>
        <tr>
            <td>Naturaliste</td>
            <td><ul><li>[X] Plusieurs parties prenantes hétérogènes</li><li>[X] Conflits substantiels</li><li>[X] Artefacts process</li><li>[ ] Cout plus élevé</li><li>[ ] Evaluation longue</li><li>[X] Accès au terrain requis</li><li>[X] Evaluation de l'utilité de l'artefact</li><li>[X] Niveau de rigueur : "On juge l'arbre à ses fruits"</li><li>[ ] Risque plus élevé pour les participants</li><li>[ ] Risque de faux positif plus faible</li></td>
            <td><ul><li>[X] Utilisateurs réels, problèmes réels et système irréel</li><li>[X] Cout faible-moyen</li></ul><ul><li>Vitesse correcte</li><li>Risque faible pour les participants</li><li>Risque élevé de faux positifs</li></ul></td>
            <td><ul><li>Utilisateurs réels, problèmes réels et systèmes réels</li><li>Cout le plus élevé</li><li>Risque le plus élevé pour les participants</li><li>Meilleure évaluation de l'utilité</li><li>Identification des effets collatéraux</li><li>Risque le moins élevé de faux positifs</li></ul></td>
        </tr>
        <tr>
            <td>Artificielle</td>
            <td><ul><li>[ ] Peu de parties prenantes similaires</li><li>[ ] Peu ou pas de conflits</li><li>[ ] Artefacts purement techniques</li><li>[ ] Cout moins élevé</li><li>[ ] Evaluation courte</li><li>[ ] Niveau de rigueur : contrôle des variables</li><li>[ ] Evaluation de l'efficacité </li><li>[ ] Risque moins élevé pendant l'évaluation</li><li>[ ] Risque de faux positif plus élevé</li></ul></td>
            <td><ul><li>Utilisateurs irréels, problèmes irréels et système irréels</li><li>Cout le moins élevé</li></ul><ul><li>Vitesse la plus élevée</li><li>Risque le moins élevé pour les participants</li><li>Risque le plus élevé de faux positifs</li></ul></td>
            <td><ul><li>Système réel, problème iréel et utilisateurs irréels</li><li>Cout moyen/élevé</li></ul><ul><li>Vitesse correcte</li><li>Risque faible-moyen pour les participants</li></ul></td>
        </tr>
    </tbody>
</table>



Au regard des critères reportés dans le framework et de leur pondération, je suis amené à choisir dans le framework de Venable et al. (2010) une évaluation *ex ante* et naturaliste. Le choix de cette stratégie possède le double d'avantage de pouvoir être menée à bien à une vitesse correcte et de limiter le risque pour les participants à l'évaluation. En revanche, cette stratégie comporte un risque plus élevé de faux positifs, qu'il s'agira de prendre en compte dans le choix et le design de la méthode d'évaluation, ainsi que dans sa réalisation. 

Ces points spécifiques font l'objet des parties suivantes. 


### Choix d'une stratégie d'évaluation pour la version alpha du prototype

Dans cette partie, il est question de choisir une stratégie d'évaluation en reportant dans le Framework de Sélection des Stratégies d'Evaluation en Design Science Research (Venable et al., 2012, p.11) les 7 critères de la version alpha du prototype de l'Open Data Canvas décrits dans [la partie précédente](7.1.1_connaissance_evaluation.md). Suite à ce report d'information, le framework permet de déduire la stratégie d'évaluation adaptée. 

Dans cette partie, je présente le framework de sélection de la stratégie d'évaluation de la version alpha du prototype (tableau ci-dessou) et en déduie le choix de la stratégie d'évaluation.


<table>
    <thead>
        <tr>
            <th colspan=2 rowspan=2>Framework de Selection des Stratégies d'Evaluation</th>
            <th>Ex ante (avant le prototypage) </th>
            <th>Ex post (après le prototypage) </th>
        </tr>
    </thead>
    <tbody>
      <tr>
            <td></td>
            <td></td>
            <td><ul><li>[ ] Evaluation formative</li><li>[ ] Cout moins élevé</li><li>[ ] Plus rapide</li><li>[ ] Evaluation du design, d'un protoype partiel ou complet</li><li>[ ] Moins de risque pour les participants durant l'évaluation</li><li>[ ] Risque plus élevé de faux positifs</li></ul></td>
            <td><ul><li>[X] Evaluation sommative</li><li>[X] Cout plus élevé</li><li>[X] Moins rapide</li><li>[X] Evaluation des instances</li><li>[X] Plus de risques pour les participants durant l'évaluation</li><li>[ ] Risque moins élevé de faux positifs</li></ul></td>
        </tr>
        <tr>
            <td>Naturaliste</td>
            <td><ul><li>[X] Plusieurs parties prenantes hétérogènes</li><li>[X] Conflits substantiels</li><li>[X] Artefacts process</li><li>[X] Cout plus élevé</li><li>[ ] Evaluation longue</li><li>[X] Accès au terrain requis</li><li>[ ] Evaluation de l'utilité de l'artefact</li><li>[X] Niveau de rigueur : "On juge l'arbre à ses fruits"</li><li>[ ] Risque plus élevé pour les participants</li><li>[ ] Risque de faux positif plus faible</li></td>
            <td><ul><li>Utilisateurs réels, problèmes réels et système irréel</li><li>Cout faible-moyen</li></ul><ul><li>Vitesse correcte</li><li>Risque faible pour les participants</li><li>Risque élevé de faux positifs</li></ul></td>
            <td><ul><li>[X] Utilisateurs réels, problèmes réels et systèmes réels</li><li>[X] Cout le plus élevé</li><li>[X] Risque le plus élevé pour les participants</li><li>Meilleure évaluation de l'utilité</li><li>Identification des effets collatéraux</li><li>Risque le moins élevé de faux positifs</li></ul></td>
        </tr>
        <tr>
            <td>Artificielle</td>
            <td><ul><li>[ ] Peu de parties prenantes similaires</li><li>[ ] Peu ou pas de conflits</li><li>[ ] Artefacts purement techniques</li><li>[ ] Cout moins élevé</li><li>[ ] Evaluation courte</li><li>[ ] Niveau de rigueur : contrôle des variables</li><li>[X] Evaluation de l'efficacité </li><li>[ ] Risque moins élevé pendant l'évaluation</li><li>[ ] Risque de faux positif plus élevé</li></ul></td>
            <td><ul><li>Utilisateurs irréels, problèmes irréels et système irréels</li><li>Cout le moins élevé</li></ul><ul><li>Vitesse la plus élevée</li><li>Risque le moins élevé pour les participants</li><li>Risque le plus élevé de faux positifs</li></ul></td>
            <td><ul><li>Système réel, problème iréel et utilisateurs irréels</li><li>Cout moyen/élevé</li></ul><ul><li>Vitesse correcte</li><li>Risque faible-moyen pour les participants</li></ul></td>
        </tr>
    </tbody>
</table>



Au regard des critères reportés dans le framework et de leur pondération, je suis amené à choisir dans le framework de Venable et al. (2010) une évaluation *ex post* et naturaliste. 

- [ ] TO-DO : expliquer les avantages et inconvénients de la stratégie d'évaluation de la version alpha



