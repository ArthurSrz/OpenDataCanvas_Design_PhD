---
auteur: Arthur Sarazin
number_sections: TRUE
output: pdf_document
---


## 1.3 Open Data : moteur de l'innovation de services dans les smart city ?


PhD Working Book (2) - p.8-11 - Débat sur les différentes définitions de l'open data + place dans les smart city
PhD Working Book (4) - p.99-100 - Etat des lieux sur la façon dont l'open data est étudié aujourd'hui


 Résumé | 
------------ | 
Il s’agit dans cette partie de retracer le parcours du mouvement de l’open data de sa création jusqu’à aujourd’hui. Par là, je compte extraire des éléments permettant de comprendre la conception de l’open data des praticiens de l’open data en France. | 

### Origines et évolutions du mouvement Open data

Le mouvement open data trouve ses origines au début des années 2000 lorsque de nouvelles revendications citoyennes émergent par rapport à l’ouverture et à l’accessibilité des données publiques. En 2006 au Royaume-Uni, Charles Arthur et Michael Cross, journalistes au Guardian lancent, un appel demandant la libération des données publiques. Cet article intitulé « Give us back our crown jewels » expose les difficultés, les incohérences, l’absurdité résultant de l’utilisation des données publiques. Cet article marque le début du mouvement open data au Royaume-Uni. De part et d’autre du monde, des démarches d’open data voient le jour, ces démarches d’ouverture et d’accessibilité des données publiques remontent bien avant les apports technologiques des NTIC, mais à un mouvement, né dans les années 1960, d’ouverture des droits d’accès aux informations administratives.

L’ouverture des données prend une nouvelle ampleur, grâce aux nouvelles opportunités amenées par les NTIC et internet. En décembre 2007, le mouvement open data tel que nous le connaissons aujourd’hui prend forme à travers un plaidoyer en faveur de l’ouverture des données publiques.

En Janvier 2009, Barack Obama signe deux mémorandums, faisant acte du fort engagement de son administration dans les démarches d’ouverture des données. Cette étape marque l’impulsion des mouvements d’OD dans le monde, le Royaume-Uni met alors en place une politique d’ouverture des données. En France, la création de la mission Etalab en 2011, lance l’accompagnement de l’Etat pour les démarches OD auprès des collectivités territoriales.

Conclusion et transition | 
------------ | 
Après avoir retracé l’histoire du mouvement politique de l’open data, il est question maintenant de développer un premier cadre théorique utilisé dans la littérature pour aborder l’objet de recherche open data : la vue relationnelle. Cette approche, qui trouve ses origines dans la théorie du management par les ressources, nous donnera un premier éclairage qui viendra établir un contraste fertile pour ma réflexion dans la mesure où il bousculera la vision du mouvement politique décrit précédemment.  | 


### L’Open data selon la vue relationnelle : le substrat de la couche de partage de connaissances d’un environnement  

L’open data peut être considéré comme le liant entre les différents prestataires de services de la ville et leurs capacités afin qu'ils puissent partager des données et trouver des synergies pertinentes qui finiront par créer de nouveaux services. Conceptuellement, nous pouvons utiliser ici la vue relationnelle (Dyer, 2000, Dyer et Singh, 1998). Ce cadre théorique considère que les ressources d'une organisation, dont l’ensemble constitue sa “valeur relationnelle”, résident dans les différentes composantes de sa relation avec d'autres organisations. Cette approche conceptuelle divise la valeur relationnelle d'une entité en 4 couches. 

![Les strates de la valeur relationnelle d'une organisation](http://opendatatales.com/wp-content/uploads/2020/03/Screen-Shot-2020-03-02-at-10.20.45.png)
#### Figure 7 : les strates de la valeur relationnelle d'une organisation (Dyer, 2000)

Parmi ces couches se trouve celle de partage des connaissances qui permet à chaque organisation de l’environnement défini de s’approprier de nouvelles données, produits, services, processus et standards. Dans les smart cities l’open data correspond au substrat de cette couche de partage des connaissances sans laquelle il ne serait pas possible de voir émerger des phénomènes de co-production de services. En effet, si l’on se rappelle la pyramide Data-Information-Knowledge-Wisdom (DIKW), les données sont les résultats d’une série d’observations, qui n’ont de valeur que si l’on peut les traduire dans un format utilisable pour qu’elles deviennent des informations ; ces informations serviront alors à répondre à certaines questions ; ces réponses pourront être alors transformées en instructions, c’est à dire en connaissances qui “rendent possible le contrôle d’un système” (Ackoff, 1989) ; enfin, la maîtrise de ces connaissances permet d’anticiper les conséquences à long terme de toute action et de les évaluer et par là, d’atteindre la sagesse. 

![Pyramide d'Ackoff](http://opendatatales.com/wp-content/uploads/2020/03/Screen-Shot-2020-03-02-at-10.21.18.png)
#### Figure 8 : pyramide d'Ackoff (1989)

Cette conception de l’open data comme substrat d’une couche de partage de connaissances communes à une multitude d’acteurs au sein d’un écosystème se retrouve dans les premières initiatives de co-production de services basées sur les jeux de données ouvertes. Celles-ci ont impliquées les pouvoirs publics et certaines communautés numériques, définies comme “un ensemble d’acteurs divers ayant des intérêts communs et collaborant à un même but sans devoir créer de liens forts entre les membres” (Bourcier, 2013). 
Ces initiatives peuvent être classées selon 3 types de collaborations  entre ces communautés numériques  et le service public : les services d’aggrégation de données par les communautés, les collaborations des communautés sur des projets publics et la production de données par les communautés (Bourcier, 2013)

- Les services d’agrégation de données par les communautés : dans ce cas, les communautés agrègent des données provenant de différentes sources pour créer de nouvelles informations. L’objectif de ces agrégations est d’encourager d’autres producteurs ou fournisseurs à ouvrir leurs données dans un format qui facilite leur interconnexion pour arriver à constituer une base de donnée suffisamment importante pour créer des applications. 
   
- Les collaborations des communautés sur des projets publics : les communautés sont dans ce cas sollicitées pour collecter des données et générer des informations qui sont ensuite rediffusées dans différents format de façon à permettre une amélioration continue des données et par là, les services inhérents à ces données

- La production de données par les communautés : dans ce dernier cas, les communautés collectent les données mais produisent aussi des données publiques les concernant. Grâce à ces données, les communautés viennent en aide au service public qui utilisent ces données pour adapter les services publics au plus près des besoins des communautés. 


Conclusion et transition | 
------------ | 
Après avoir tiré de la vue relationnelle l’hypothèse selon laquelle l’open data constitue une couche de connaissances partagées entre les parties prenantes de la smart city sur laquelle ils peuvent se baser pour co-créer des services, je me propose dans cette sous-partie d’offrir une autre approche de l’open data. Je sollicite cette fois-ci la théorie des biens communs. Cette approche institutionnaliste exprime en substance l’idée que pour certains biens, dits biens communs, il est préférable de laisser la gestion au main d’institution auto-organisées plutôt qu’à l’Etat ou au marché. J’explore dans cette sous-partie l’hypothèse selon laquelle l’open data est un bien commun.  | 

### L'open data selon la théorie des biens communs 

**L’évolution de l’application de la théorie des biens communs : des ressources naturelles aux données numériques**

La théorie des biens communs s’est construite à l’origine pour étudier les ressources naturelles partagées entre plusieurs acteurs comme l’eau, les forêts ou les zones de pêche ainsi que les modes de gestion mis en place pour garantir la durabilité de celles-ci. La particularité de ces biens réside dans leur forte exposition à des comportements humains paradoxaux en ce qu’ils créent des dilemmes sociaux (Hess, 2012). Pour mieux saisir la nature de ces dilemmes, prenons l’exemple des zones de pêche. 
Ces zones sont à la libre disposition d’un grand nombre de pêcheurs qui doivent les partager. Cette situation génère une compétition entre les pêcheurs qui risque de mener à une surexploitation de la ressource marine et au final, à son épuisement. Ainsi, dans ce type de situation, si aucune règle de partage de la ressource n’est mise en place, la ressource risque de disparaître. On connaît plus couramment ces scénarios sous le nom de “tragédie des communs” (Hardin, 1998). Pour éviter ces tragédies, les chercheurs ont observé la mise en place spontanée de mécanismes d’action collective et d’auto-organisation par les acteurs cherchant à exploiter la ressources. Ceux-ci régissent les relations entre des acteurs au fort capital social. L’action collective est ici conçue comme ce qui émerge quand  “des efforts de deux individus ou plus sont nécessaires pour aboutir à un résultat” (Sandler, 1992), avec la particularité que ces efforts doivent être volontaires. L’auto-gouvernance naît ici de la combinaison de l’action collective avec “d’une part la connaissance et volonté des acteurs et, d’autre part, le support de dispositifs institutionnels“ (Hess et Ostrom, 2007). Enfin, le capital social est ici compris comme la valeur du réseau de chaque acteur et de l’inclinaison des acteurs faisant partie des mêmes réseaux à faire des choses pour les autres.
  Parmi les travaux les plus éminents de ce courant dit traditionnel de l’étude des communs, on trouve l’ouvrage d’Elinor Ostrom, Governing the commons (1990). Sur la base d’un profond travail théorique et de 5 études de cas, la future prix Nobel d’économie identifie les 8 principes inhérents au design d’institutions en charge de la gestion et conservation de ressources partagées : 
- Délimiter rigoureusement les frontières de l’institution
- Adapter les règles en vigueur au contexte local
- Les individus soumis à ces règles ont la possibilité de modifier ces règles
- Les autorités extérieures doivent respecter le droit des communautés locales à fixer leurs propres règles de gestion 
- Mettre en place un système d’auto-supervision du comportement des membres de la communauté
- Créer un système de sanction graduel
- Les membres de la communauté ont accès à des mécanismes de résolution de conflit 
- Les activités menées par le collectif sont organisées par une structure avec différents niveaux. 


Ce courant traditionnel centré sur l’étude de biens tangibles, a été étendu dans le milieu des années 1990 à un bien intangible : la connaissance. Cette extension de la théorie des biens communs fait suite à la prise de conscience simultanée d’internautes que la connaissance partagée et distribuée en ligne répondait à l’ensemble des critères des biens communs (Hess et Ostrom, 2007). Le contenu produit par Wikipédia se présente comme un cas d’école en la matière. Toute page Wikipédia peut être produite par n’importe quel acteur et son accès, sa réutilisation et sa modification s’avère être totalement libre. Quiconque le souhaite peut reprendre le contenu d’une page Wikipédia pour les utiliser. En ce sens, le contenu est une ressources partagée. Or, ce libre accès et modification implique un risque pour cette connaissance qui peut être dévoyée, modifiée et faussée à des fins personnelles. Nous retrouvons ici un dilemme social intrinsèque aux biens communs. Dès lors, pour y faire race, Wikipédia a mis en place un ensemble de règles pour contrôler le contenu créé par les contributeurs et s’assurer de leur fiabilité. 
Bien qu’il soit tentant de transposer intégralement les découvertes faites sur les biens communs tangibles aux communs de la connaissance, les analystes des biens communs restent prudents et adoptent une posture intellectuelle de questionnement perpétuel pour savoir, d’un côté, quelles sont les similitudes entre les biens communs et les communs de la connaissance, et leurs différences de l’autre. Cette posture nourrit encore les travaux sur les communautés virtuelles qui se forment autour de ces connaissances (Rheingold, 1993), sur la particularité des dilemmes sociaux inhérents à la connaissance sur le web et sur les nouveaux régimes de propriétés créés pour ces communs de la connaissance. 

A présent, il s’agit de savoir si les données peuvent être considérées d’un point de vue théorique et pratique comme des communs de la connaissance. Si aucun avis tranché n’a été donné, certains chercheurs ont mis en évidence un faisceau d’indices qui tendent à confirmer cette affirmation. 
D’un point de vue théorique tout d’abord, l’ouvrage de Hess et Ostrom (2007), pionnier sur les communs de la connaissance donne la définition suivante de la connaissance : “la connaissance est comprise comme l’ensemble des idées, informations et données dans leurs formes possibles “. Elles justifient l’inclusion des données dans cette définition en rappelant les travaux de Davenport, Thomas et Prusak (1998) pour lesquels “la connaissance est un dérivé de l’information et l’information un dérivé de la donnée” et de Machlup (1983) qui aborde la donnée comme un morceau brut d’information, l’information comme la donnée contextualisée et la connaissance comme l’assimilation de la compréhension qui peut être faite de cette information. En interprétant ces éléments, nous pouvons affirmer que Hess et Ostrom (2007) attribuent la dénomination de communs de la connaissance aux données en suivant deux syllogismes : si la connaissance est un bien commun et qu’elle est un dérivé de l’information, alors l’information est un bien commun ; si l’information est un bien commun et que la donnée est un dérivé de l’information, alors la donnée est un bien commun. 

D’un point de vue pratique, la législation française amène à voir certaines données, les données publiques, comme un bien commun sans les qualifier directement comme tel. Crosnier et Vidal (2017) rappellent à juste titre que la loi pour la République Numérique du 7 octobre 2016 considère “l'accès aux données publiques (comme allant) au-delà de la gratuité d’accès et demande que les données soient fournies dans un format ouvert, normalisé qui les rendent réutilisables. L'objectif est à la fois économique (susciter de nouvelles applications) et politique (permettre aux citoyens et leurs associations d’exercer le contrôle avec les données)”. On peut rapprocher l’objectif économique de l’exploitation qui peut être faite d’un bien commun et l’objectif politique de la nécessaire constitution d’une communauté pour défendre ce bien contre les enclosures. 
Autre indice : les plateformes open data créées par les collectivités suite à la loi pour la République Numérique. Larroche et al. (2018) considèrent qu’au-delà de faciliter la mise à disposition des données ouvertes, ces plateformes incarnent une tentative de créer et d’organiser un espace ouvert à tous les acteurs qui souhaitent partager leurs données. Ce qui leur permet de conclure : “nous pouvons rapprocher ces plateformes des « communs de la connaissance » si l’on suit la définition de Serge Proulx (2015), pour qui ces communs sont des corpus de savoirs et d’informations que l’on veut largement ouverts (open data) et directement accessibles au plus grand nombre d’utilisateurs sur la base de la gratuité du service.
Enfin, on recense de nombreux travaux sur la captation de données de nature publique à des fins privés. Ces pratiques renvoient aux phénomènes d’enclosures. Dans un de ses rapports, la Commission Nationale de l’Informatique et des Libertés (2017) alertait les pouvoirs publics de la captation massive de données par les opérateurs privés du numérique et des réseaux. Le projet Quayside, porté par une filière de Google à Toronto est un exemple phare de cette captation de données publiques à des fins privés. Cette expérimentation donne libre champ à Google pour mettre en place dans un quartier des capteurs, exploiter les données de ces capteurs et adapter les services du quartier en fonction. L’analyse faite de l’utilisation des données issues des recherches biomédicales par Heller (1998) renvoie à la même dynamique : alors que ces données relèvent pour certaines de problèmes de santé public, les laboratoires se sont appropriées ces données et la connaissances liée grâce à des droits de propriété intellectuels excessivement protecteurs. Selon cette analyse, ces protections sont aujourd’hui à l’origine d’une sous-utilisation des données et d’un manque à gagner dans l’évolution de certains traitement médicaux. 
Ces trois indices nous amènent à poser l’hypothèse que la donnée, dans son essence, peut être dans certains cas considérées comme un communs de la connaissance. 

Transition | 
------------ | 
Dans ce paragraphe, nous avons tout d’abord retracé l’évolution de la théorie des biens communs jusqu’à ses récentes déclinaisons qui s’intéressent à certains types de biens immatériels comme la connaissance. Puis, nous avons démontré qu’il existe un faisceau d’indices permettant d’affirmer que la donnée peut être considérée comme un commun de la connaissance. Dans la prochaine paragraphe, il s’agira de savoir si les données ouvertes telles qu’elles sont définies et produites en France sont des communs de la connaissance . Pour cela, nous évaluerons si les données ouvertes répondent aux 3 traits distinctifs des communs de la connaissance : un régime de propriété partagé, des barrières à l’entrée couplées à des règles à suivre pour tout acteur souhaitant être impliqué dans la gestion du commun et un ensemble de responsabilités partagées entre les acteurs gestionnaires de la donnée.
| 

**Les données ouvertes en France : des communs de la connaissance non-identifiés ?**
Les données ouvertes qui sont au coeur de notre analyse répondent-elles bien aux critères des communs de la connaissance ? Larroche et al. (2018) ont mené cette analyse en s’interrogeant sur les critères de propriété, de participation et de responsabilité liés à l’open data. 
	
Sur les critères de propriété, Larroche et al. (2018) affirment que les licenses ouvertes qui s’appliquent aux données ouvertes sont généralement suffisantes pour protéger les données des risques d’enclosures et remplir les critères de propriété des biens communs. En france, nous pouvons prendre l’exemple de la license d’Etalab, la plus communément utilisée par les collectivités publiques, qui s’insprie de la license Creative Commons dans sa version CC-BY 2.0, citée par Hess et Ostrom (2007) comme une matérialisation d’un régime de propriété pouvant correspondre à un commun de la connaissance. 

**Les implications de l’open data**
En réaction à l’émergence de premiers services créés à travers la collaboration d’acteurs publics avec des communautés numériques (2013), la littérature a noté un changement dans les interactions entre les partenaires participant à la production de services publics. D’un système de production basé sur la délégation de services publics où les pouvoirs publics de la ville exercent toute l’autorité qui leur est conférée par les élections et leur capacité à solliciter des moyens autour de l’intérêt général, on s’oriente vers un système de co-production dans lequel les acteurs participent aussi bien à la conception du service qu’à la gouvernance de celle-ci. (Bourcier, 2013 ; Larroche et al., 2018 ; Mabi, 2014) 

Dans ce cadre, certains auteurs ont vu dans l’open data tous les éléments fondamentaux des biens communs  (tels que décrits par Elinor Ostrom et Charlotte Hess (2007) : 

le libre accès au bien question, matérialisé dans l’Open data par les portails  
des règles de gestion communautaires pour assurer la permanence d’un travail coopératif et protéger le bien d’un risque d’enclosure, matérialisé par la license ouverte qui délimite les conditions d’utilisation des jeux de données
la participation active d’une communauté dans le développement et la protection d’un bien, matérialisés par les communautés numériques  (Rheingold, 2015) et les systèmes de co-production de services décrits ci-dessus. 

Or, d’après les analyses des portails Open data en France (Larroche et al., 2018 ; Mabi, 2014), si le premier élément des biens communs est bien présent, le deuxième prête à discussion car il se base entièrement sur la license qui n’est qu’un aspect de la gouvernance de l’Open data et le troisième constitue un réel “point d’achoppement” (Larroche et al., 2018). En effet, les collectivités se contentent jusqu’à présent de simplement mettre en avant sur des pages dédiées les applications issues de réutilisations de jeux de données sans pour autant mettre en avant un rôle quelconque des réutilisateurs dans la mise à disposition des jeux de données. Autrement dit, les utilisateurs des jeux de données sont considérés jusqu’à présent par les collectivités comme de simplement consommateurs de données et non comme des acteurs participant à la gouvernance des jeux de données ouverts (Larroche et al., 2018). 
	
Face à ce constat, on pourrait émettre l’hypothèse qu’il existe des communautés de réutilisateurs possédant leurs propres règles de gouvernance mais situées hors des portails Open data (Larroche et al., 2018). Or, cette hypothèse semble peu probable étant donné la faible réutilisation des jeux de données, largement constatée dans la littérature (Dawes et al., 2016 ; Gascò-Hernandez et al., 2016 ; Braunschweig et al., 2012 ; Ruijer et al., 2017 ; Welle Donker et van Loenen, 2017 ; Recupero et al., 2016 ; Le Corf, 2016). 


Conclusion et transition | 
------------ | 
Dans les deux sous-parties précédentes, nous avons repris deux approches théoriques utilisées dans la littérature pour comprendre l’open data. Or, il était question de l’open data au sens géneral et non dans un cadre géographique ou organisationnel particulier. Dès lors, dans cette sous-partie, je vise à démontrer que l’objet open data dans le contexte de l’innovation de services dans la smart city possède des caractériques particulières qu’il s’agira pour moi de mettre en évidence.| 

### L’open data dans les smart cities : un atout pour l’innovation de services à concevoir

**La disponibilité des données pour toutes les parties prenantes de la ville intelligente comme condition préalable à l’émergence d’une smart city**
D’après Gil-Garcia et al., (2015), les données sont à la fois l'une des quatre dimensions et l'un des dix éléments clés d'une Smart City. Ils spécifient que cette dimension et ce composant peuvent se concevoir comme des facilitateurs de toutes les autres dimensions et composants d’une Smart City. 

Dans la même veine, certains auteurs considèrent même les données et la technologie comme le véritable cœur de l'intelligence urbaine. Pour Harrison et al., (2010), les villes intelligentes sont des «zones urbaines qui exploitent des données opérationnelles telles que celles provenant des embouteillages, des statistiques de consommation d'énergie et des événements de sécurité publique pour optimiser le fonctionnement des services de la ville ».

Cela ne veut pas dire que l'objectif ultime des villes intelligentes est d'exploiter les données opérationnelles. Plutôt, cela implique qu'il y a des conditions préalables essentielles pour qu'une ville soit considérée comme “smart”. Gil-Garcia et al., (2015) en énumèrent trois:

- la ville est instrumentée: des données en temps réel provenant de capteurs physiques et virtuels sont captées
- la ville possède une plateforme informatique permettant d'interconnecter et d'intégrer des données ainsi que de fluidifier la communication d’informations entre les différents services de la ville.
- la ville possède des logiciels d'analyse complexe, de modélisation, de simulation, d’optimisation et de visualisation qui sont utilisés pour prendre de meilleures décisions opérationnelles.

Par conséquent, une ville est intelligente une fois que les capteurs peuvent capturer des données, que ces données sont mises à la disposition de tous les acteurs contribuant à la conception de services innovants et qu'elles sont exploitées par des technologies. 

**L’open data au service de l’innovation de services dans les smart cities : vers une nouvelle définition ? **

Les données captées sur le comportement des villes proviennent de nombreuses sources. Par exemple, les données sur la circulation routière au sein des villes sont à la fois récoltées par des acteurs privés comme Uber qui, avec les données GPS de ses taxis, possède une connaissance approfondie des flux de circulation ; par des acteurs publics comme les municipalités qui possèdent les données sur l’ensemble des travaux en cours et à venir sur les voiries et donc sur les déviations des flux ; des acteurs issus de la société  civile avec Waze par exemple où les citoyens indiquent les zones de ralentissement ou de danger. 

Cet exemple montre bien que les données ouvertes (open data) ne proviennent pas uniquement du gouvernement comme les principes de Sébastopol l’indique dans la définition originelle de l’Open data. Dès lors, il apparaît judicieux d’élargir la définition de l’Open data dans le cadre des Smart City pour embrasser l’ensemble des jeux de données, qu’ils proviennent de source publique, privée ou civile, et qui sont mis à disposition de l’ensemble des parties prenantes des Smart City via une plateforme informatique (Gil-Garcia et al., 2015) 

Dans ce cadre, l’open data ne concerne plus uniquement le mouvement de libération des jeux de données détenus par des acteurs publics mais aussi celui de la captation de jeux de données détenus par des acteurs privés mais qui décrivent des phénomènes d’intérêt général à l’échelle d’une smart city. Alors, on aboutirait à une expansion du phénomène d’open data. Ce dernier prendrait la forme d’un double mouvement qui rejoint l’articulation faite par Schön (1967) entre les concepts de «technology-push» et de «need-pull». 

Le concept de “technology-push” sous-tend l'idée que ce qui stimule l'innovation est l'adoption d'une nouvelle technologie existante et disponible. Nous pouvons lier ce concept à celui de l’Open data tel que défini par les principes de Sébastopol : en publiant des données et des outils pour les utiliser sur une plateforme, les fonctionnaires ont «poussé la technologie» pour déclencher l'innovation. Cela montre à l’ensemble de l’écosystème d’une Smart City que les données existent et sont disponibles. Mais, comme l'ont suggéré certains auteurs (Fischer, 1980), le “technology-push” n’est que le première pièce du puzzle de l’innovation car une innovation ne naît que lorsque un moyen (symbolisé ici par les jeux de données publics et les plateformes) rencontre un besoin. Or, cette deuxième partie rentre rarement en compte dans les stratégies des acteurs publics en charge de l’open data, comme nous le verrons dans la prochaine sous-partie. Ils se concentrent uniquement sur la libération des jeux de données publics, laissant de côté le recensement d’autres jeux de données provenant de sources externes et des besoins des acteurs derrières ces sources, qui rejoint le concept de “need-pull” de Schon (1967). Pour que l’Open data puisse aboutir à de véritables innovations de services, les données recueillies par des acteurs privés, non gouvernementaux ou citoyens ainsi que les besoins de ces acteurs doivent être pris en compte (need-pull) et confronté aux jeux de données publics au sein d’une même plateforme (technology-push). 

### Niveau infra-organisationnel

PhD Working Book (6) - p. 60-61 - première évocation de l'open data work (contre le niveau industriel)

### Niveau industriel, territorial et sociétal

PhD Working Book (1) - 2017 (p.15-19)
PhD Working Book (6) - p.20-22/25/31/33 - Traduction de Dawes et al. (2016) qui explique l'absence d'usage des données malgré les évidents bénefices.


### Niveau inter-organisationnel

- PhD Working Book (6) - p.49 - Constat partagé (Ruijer, Dawes, Dekkers, Pollock, Pardo et Cresswell) que les analyses du travail de l'open data au niveau inter-organisationnel (écosystème) peuvent apporter un supplément de complexité utile aux praticiens. 
