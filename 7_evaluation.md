# 7. Evaluations visant à estimer la capacité d'Innodata à faciliter les interactions entre les opérateurs de l'open data et les *data spaces*

Dans le chapitre précédent, nous avons détaillé le **processus de prototypage** qui nous a amené à concevoir l'**artefact**. Aussi avons-nous décrit formellement la structure de cet artefact et expliquer en quoi ces différents éléments pourraient répondre aux différents aspects de la question. Ces explications sont autant de réponses temporaires dont il s'agit d'évaluer la **pertinence empirique** et la **rigueur scientifique** dans ce chapitre. 

Nous avons mené des évaluations dans le but d'estimer la capacité des différentes versions d'Innodata (i.e les artefacts) à conduire l'innovation de services issue de l'open data dans les villes intelligentes vers l'idéal qu'elles se sont fixées. En effet, le choix de la *design science research methodology* suppose d'adopter une démarche intrinséquement itérative dans laquelle une première réponse artefactuelle est apportée avant d'être évaluée. Si la réponse est suffisamment pertinente empiriquement et rigoureuse scientifiquement, alors la recherche s'arrête. Dans le cas contraire, la question de recherche est précisée et un nouveau cycle de recherche démarre. Cette nouvelle itération apporte une deuxième réponse artefactuelle qui est à son tour évaluée, et ainsi de suite. 

- [ ] Décrire la structure générale des évaluations menées à la fin de chaque cycle de recherche. 
- [ ] Dédoubler en évaluation de la pertinence empirique et de la rigueur scientifique 
- [ ] Expliquer le lien avec la partie prototypage et avec la première étape du nouveau cycle 
- [ ] Terminer sur le "quand s'arrêter"
